{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Contas Médicas.ipynb",
      "provenance": [],
      "mount_file_id": "1e_rmufqIymN5tHw7N6rk5UHkwyC6XVaY",
      "authorship_tag": "ABX9TyP7Wy/4LgXyxPmP7GCwlwow"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJdv33QHUelP"
      },
      "source": [
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPMCPu5rE3u2"
      },
      "source": [
        "#!wget https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsxMrmtME6sR"
      },
      "source": [
        "#!tar xf spark-3.0.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-YBfhugE90y"
      },
      "source": [
        "#!pip install -q findspark"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjhFQFsAFACA"
      },
      "source": [
        "#!pip install -q pyspark"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvLhFhknUtcU"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4pVtIHAFLhZ"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANK49Qm2F8ld"
      },
      "source": [
        "spark #verificar se há o objeto spark "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOpirPNnHnrv"
      },
      "source": [
        "df = spark.read.csv(\"/content/drive/My Drive/dados/GO AMB/2019_det_amb.csv\", header=True, sep=\",\")\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXxQkDm1Akcu"
      },
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import FloatType\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OUz2aeuAqKx"
      },
      "source": [
        "def to_value(v):\n",
        "    try:\n",
        "        return float(v.replace(\",\",\".\"))\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "udf_to_value = F.udf(to_value, FloatType())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78t1FVljAswl"
      },
      "source": [
        "dfmod= df.withColumn('VL_PROCEDIMENTO', udf_to_value(df[\"VL_PROCEDIMENTO\"]))\\\n",
        "   .withColumn('QT_PROCEDIMENTO', udf_to_value(df[\"QT_PROCEDIMENTO\"]))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8tFJ3QxAt8W"
      },
      "source": [
        "soma = dfmod.select('CD_TUSS_PROCEDIMENTO', F.when(dfmod['VL_PROCEDIMENTO'] < 5000, 0).alias('Valor'))"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIGeVcTxAzSu"
      },
      "source": [
        "\n",
        "spark.stop()"
      ],
      "execution_count": 133,
      "outputs": []
    }
  ]
}